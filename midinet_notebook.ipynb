{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "runescape-midinet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7bYN8NLDYtp"
      },
      "source": [
        "# Midinet Music Generator\n",
        "## Setting up\n",
        "First we install the required dependencies through pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc_vHhHYdqay"
      },
      "source": [
        "pip install mido"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCBjAQUlDH7W"
      },
      "source": [
        "Then mount to Google Drive and change the directory to runescape-midinet or where ever the root folder is located"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odcLgt0WbWrr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4oQsSbD967v"
      },
      "source": [
        "cd drive/MyDrive/runescape-midinet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAw8iQelDfqA"
      },
      "source": [
        "Now we can import the methods we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23dSwXVz-AwK"
      },
      "source": [
        "from train import train\n",
        "from generate import generate\n",
        "from preprocess import process_midis\n",
        "from download import download_dataset\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-rtXJrOFblD"
      },
      "source": [
        "## Downloading the datasets\n",
        "\n",
        "To start off, we need to download our datasets\n",
        "\n",
        "We will be using two different datasets: the Runescape OST and the Lahk MIDI Dataset\n",
        "\n",
        "Arguments:\n",
        "* dataset: the dataset to download (rs_ost or lahk)\n",
        "* output_directory: the directory for the downloaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYVnFLfcFeGG"
      },
      "source": [
        "dataset = 'rs_ost'\n",
        "output_directory = 'rs_ost_raw'\n",
        "\n",
        "download_dataset(dataset, output_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TZ_n3CoF7fg"
      },
      "source": [
        "dataset = 'lahk'\n",
        "output_directory = 'lahk_raw'\n",
        "\n",
        "download_dataset(dataset, output_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axmZrbdWFsRP"
      },
      "source": [
        "## Preprocessing the datasets\n",
        "\n",
        "Before we start start training, we must preprocess the MIDIs from the downloaded datasets into a tokenized sequence\n",
        "\n",
        "*(note: this may take several hours depending on the size of the dataset)*\n",
        "\n",
        "Arguments:\n",
        "* input_directory: the directory containing the downloaded MIDI files\n",
        "* output_directory: the directory to save the preprocessed dataset to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiZfVfbfFrmI"
      },
      "source": [
        "input_directory = 'rs_ost_raw'\n",
        "output_directory = 'rs_ost'\n",
        "\n",
        "process_midis(input_directory, output_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX3HInvzGJ8O"
      },
      "source": [
        "input_directory = 'lahk_raw'\n",
        "output_directory = 'lahk'\n",
        "\n",
        "process_midis(input_directory, output_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blt2GJ1vEUiq"
      },
      "source": [
        "## Model Parameters\n",
        "\n",
        "These are the parameters that control the model\n",
        "\n",
        "* vocab_size: the size of the vocabulary (do not change)\n",
        "* embedding_size: the size of embedding layer\n",
        "* sequence_length: the length of the input sequence\n",
        "* num_blocks: the number of decoder blocks\n",
        "* num_heads: the number of attention heads\n",
        "* feed_forward_dim: the dimension size for the feed forward layers\n",
        "* dropout: the dropout rate\n",
        "* learning_rate: the learning rate\n",
        "* batch_size: the batch size used during training\n",
        "* dataset: the dataset that will be used for training and inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-fr3WwKEXTF"
      },
      "source": [
        "parameters = {\n",
        "    \"vocab_size\": 517,\n",
        "    \"embedding_size\": 512,\n",
        "    \"sequence_length\": 2048,\n",
        "    \"num_blocks\": 6,\n",
        "    \"num_heads\": 8,\n",
        "    \"feed_forward_dim\": 1024,\n",
        "    \"dropout\": 0.10,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 2,\n",
        "    \"dataset\": \"rs_ost\"\n",
        "}\n",
        "\n",
        "with open('parameters.json', 'w') as f:\n",
        "    json.dump(parameters, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Bg3n8xDt-Z"
      },
      "source": [
        "## Training\n",
        "\n",
        "Once we have our datasets ready, we can start training our model\n",
        "TensorBoard graphs to track loss and accuracy can be under the logs directory.\n",
        "\n",
        "Arguments:\n",
        "* epochs: number of epochs to train the model for\n",
        "* save_directory: the directory the model will be saved to\n",
        "* restore_from_checkpoint: whether to restore from the last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ6Ygkew-K1A"
      },
      "source": [
        "epochs = 1\n",
        "save_directory = 'midinet_model'\n",
        "restore_from_checkpoint = False\n",
        "\n",
        "train(epochs, save_directory, restore_from_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgUMplTDDxhn"
      },
      "source": [
        "## Inference\n",
        "\n",
        "After training, we can use the model for inference to generate MIDI music\n",
        "\n",
        "The model will be given random samples from the dataset specified in parameters.json as the seed to begin inference with\n",
        "If you wish to draw samples from a different dataset for inference, simply change the dataset parameter in parameters.json\n",
        "\n",
        "*(note: make sure the sequence length specified in model parameters matches the sequence length for the model being used)*\n",
        "\n",
        "Arguments:\n",
        "* song_length: the number of song tokens to be generated\n",
        "* top_k: the k value for selecting top k predictions\n",
        "* save_directory: the directory to load the saved model from\n",
        "* inclusive: whether or not to include the starting seed in the generated MIDI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIZj31lY-raF"
      },
      "source": [
        "song_length = 2500\n",
        "top_k = 8\n",
        "save_directory = 'midinet_model'\n",
        "inclusive = False\n",
        "\n",
        "generate(song_length, top_k, save_directory, inclusive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "If you downloaded the trained model, then you will most likely want to use the cell below instead assuming you moved the downloaded model directory to the project root folder and named it 'midinet_model_trained'."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "song_length = 2500\n",
        "top_k = 8\n",
        "save_directory = 'midinet_model_trained'\n",
        "inclusive = False\n",
        "\n",
        "generate(song_length, top_k, save_directory, inclusive)"
      ]
    }
  ]
}